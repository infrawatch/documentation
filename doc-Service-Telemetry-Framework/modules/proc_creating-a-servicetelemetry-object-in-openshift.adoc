// Module included in the following assemblies:
//
// <List assemblies here, each on a new line>

// This module can be included from assemblies using the following include statement:
// include::<path>/proc_creating-a-servicetelemetry-object-in-openshift.adoc[leveloffset=+1]

// The file name and the ID are based on the module title. For example:
// * file name: proc_doing-procedure-a.adoc
// * ID: [id='proc_doing-procedure-a_{context}']
// * Title: = Doing procedure A
//
// The ID is used as an anchor for linking to the module. Avoid changing
// it after the module has been published to ensure existing links are not
// broken.
//
// The `context` attribute enables module reuse. Every module's ID includes
// {context}, which ensures that the module has a unique ID even if it is
// reused multiple times in a guide.
//
// Start the title with a verb, such as Creating or Create. See also
// _Wording of headings_ in _The IBM Style Guide_.


[id="creating-a-servicetelemetry-object-in-openshift"]
== Creating a ServiceTelemetry object in {OpenShiftShort}

Create a `ServiceTelemetry` object in {OpenShiftShort} to result in the creation of supporting components for a {Project} deployment. For more information, see xref:overview-of-the-servicetelemetry-object[].

.Procedure

. To create a `ServiceTelemetry` object that results in a default {ProjectShort} deployment, create a `ServiceTelemetry` object with an empty `spec` object:
+
[source,bash]
----
oc apply -f - <<EOF
apiVersion: infra.watch/v1beta1
kind: ServiceTelemetry
metadata:
  name: default
  namespace: service-telemetry
spec: {}
EOF
----
+
Creating a default `ServiceTelemetry` object results in a {ProjectShort} deployment with the following defaults:
+
[source,yaml]
----
apiVersion: infra.watch/v1beta1
kind: ServiceTelemetry
metadata:
  name: default
spec:
  alerting:
    enabled: true
    alertmanager:
      storage:
        strategy: persistent
        persistent:
          storageResources: {}
          storageSelector: {}
          pvcStorageRequest: 20G
  backends:
    metrics:
      prometheus:
        enabled: true
        scrapeInterval: 10s
        storage:
          strategy: persistent
          persistent:
            storageResources: {}
            storageSelector: {}
            pvcStorageRequest: 20G
    events:
      elasticsearch:
        enabled: false
        storage:
          strategy: persistent
          persistent:
            pvcStorageRequest: 20Gi
  graphing:
    enabled: false
    grafana:
      ingressEnabled: false
      adminPassword: secret
      adminUser: root
      disableSignoutMenu: false
  transports:
    qdr:
      enabled: true
  highAvailability:
    enabled: false
  clouds:
    - name: cloud1
      metrics:
        collectors:
          - collectorType: collectd
            subscriptionAddress: collectd/telemetry
          - collectorType: ceilometer
            subscriptionAddress: anycast/ceilometer/metering.sample
      events:
        collectors:
          - collectorType: collectd
            subscriptionAddress: collectd/notify
          - collectorType: ceilometer
            subscriptionAddress: anycast/ceilometer/event.sample
----

. Optional: To create a `ServiceTelemetry` object that results in collection and storage of events for the default cloud, enable the ElasticSearch backend:
+
[source,yaml]
----
oc apply -f - <<EOF
apiVersion: infra.watch/v1beta1
kind: ServiceTelemetry
metadata:
  name: default
  namespace: service-telemetry
spec:
  backends:
    events:
      elasticsearch:
        enabled: true
EOF
----

. To view the {ProjectShort} deployment logs in the Service Telemetry Operator, use the `oc logs` command:
+
[source,bash]
----
oc logs --selector name=service-telemetry-operator -c ansible
----
+
[options="nowrap", subs="+quotes"]
----
PLAY RECAP *********************************************************************
localhost                  : ok=55   changed=0    unreachable=0    failed=0    skipped=16   rescued=0    ignored=0
----

. View the pods and the status of each pod to determine that all workloads are operating nominally:
+
NOTE: If you set `backends.events.elasticsearch.enabled: true`, the notification Smart Gateways will `Error` and `CrashLoopBackOff` for a period of time before ElasticSearch starts.
+
[source,bash,options="nowrap",subs="+quotes"]
----
$ oc get pods

NAME                                                      READY   STATUS    RESTARTS   AGE
alertmanager-default-0                                    2/2     Running   0          38s
default-cloud1-ceil-meter-smartgateway-58d8876857-lbf9d   1/1     Running   0          159m
default-cloud1-coll-meter-smartgateway-8645d64f5f-rxfpb   2/2     Running   0          159m
default-interconnect-79d9994b5-xnfvv                      1/1     Running   0          167m
elastic-operator-746f86c956-jkvcq                         1/1     Running   0          6h23m
interconnect-operator-5b474bdddc-sztsj                    1/1     Running   0          6h19m
prometheus-default-0                                      3/3     Running   1          5m39s
prometheus-operator-7dfb478c8b-bfd4j                      1/1     Running   0          6h19m
service-telemetry-operator-656fc8ccb6-4w8x4               2/2     Running   0          98m
smart-gateway-operator-7f49676d5d-nqzmp                   2/2     Running   0          6h21m
----
