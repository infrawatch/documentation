[id="primary-parameters-of-the-servicetelemetry-object_{context}"]
= Primary parameters of the ServiceTelemetry object

[role="_abstract"]
You can set the following primary configuration parameters of the `ServiceTelemetry` object to configure your {ProjectShort} deployment:

* `alerting`
* `backends`
* `clouds`
* `graphing`
* `highAvailability`
* `transports`

[id="backends_{context}"]
[discrete]
== The backends parameter

Set the value of the `backends` parameter to allocate the storage back ends for metrics and events, and to enable the Smart Gateways that the `clouds` parameter defines. For more information, see xref:clouds_assembly-installing-the-core-components-of-stf[].

You can use Prometheus as the metrics storage back end and Elasticsearch as the events storage back end. The Service Telemetry Operator can create custom resource objects that the Prometheus Operator watches to create a Prometheus workload. You need an external deployment of Elasticsearch to store events.

[discrete]
=== Enabling Prometheus as a storage back end for metrics

To enable Prometheus as a storage back end for metrics, you must configure the `ServiceTelemetry` object.

.Procedure

. Edit the `ServiceTelemetry` object:
+
[source,bash]
----
$ oc edit stf default
----

. Set the value of the backends.metrics.prometheus.enabled parameter to `true`:
+
[source,yaml]
----
apiVersion: infra.watch/v1beta1
kind: ServiceTelemetry
metadata:
  name: default
  namespace: service-telemetry
spec:
  [...]
  backends:
    metrics:
      prometheus:
        enabled: true
----

[id="backends-configuring-persistent-storage-for-prometheus_{context}"]
[discrete]
=== Configuring persistent storage for Prometheus

Set the additional parameters in `backends.metrics.prometheus.storage.persistent` to configure persistent storage options for Prometheus, such as storage class and volume size.

Define the back end storage class with the `storageClass` parameter. If you do not set this parameter, the Service Telemetry Operator uses the default storage class for the {OpenShift} cluster.

Define the minimum required volume size for the storage request with the `pvcStorageRequest` parameter. By default, Service Telemetry Operator requests a volume size of `20G` (20 Gigabytes).

.Procedure

. List the available storage classes:
+
[source,bash,options="nowrap"]
----
$ oc get storageclasses
NAME                 PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
csi-manila-ceph      manila.csi.openstack.org   Delete          Immediate              false                  20h
standard (default)   kubernetes.io/cinder       Delete          WaitForFirstConsumer   true                   20h
standard-csi         cinder.csi.openstack.org   Delete          WaitForFirstConsumer   true                   20h
----

. Edit the `ServiceTelemetry` object:
+
[source,bash]
----
$ oc edit stf default
----

. Set the value of the `backends.metrics.prometheus.enabled` parameter to `true` and the value of `backends.metrics.prometheus.storage.strategy` to `persistent`:
+
[source,yaml]
----
apiVersion: infra.watch/v1beta1
kind: ServiceTelemetry
metadata:
  name: default
  namespace: service-telemetry
spec:
  [...]
  backends:
    metrics:
      prometheus:
        enabled: true
        storage:
          strategy: persistent
          persistent:
            storageClass: standard-csi
            pvcStorageRequest: 50G
----

[discrete]
=== Enabling Elasticsearch as a storage back end for events

[NOTE]
====
Previous versions of {ProjectShort} managed Elasticsearch objects for the community supported Elastic Cloud on Kubernetes Operator (ECK). Elasticsearch management functionality is deprecated in {ProjectShort} 1.5.3. You can still forward to an existing Elasticsearch instance that you deploy and manage with ECK, but you cannot manage the creation of Elasticsearch objects. When you upgrade your {ProjectShort} deployment, existing Elasticsearch objects and deployments remain, but are no longer managed by {ProjectShort}.

ifeval::["{build}" == "downstream"]
For more information about using Elasticsearch with {ProjectShort}, see the Red Hat Knowledge Base article https://access.redhat.com/articles/7031236[Using Service Telemetry Framework with Elasticsearch].
endif::[]

====

To enable events forwarding to Elasticsearch as a storage back end, you must configure the `ServiceTelemetry` object.

.Procedure

. Edit the `ServiceTelemetry` object:
+
[source,bash]
----
$ oc edit stf default
----

. Set the value of the `backends.events.elasticsearch.enabled` parameter to `true` and configure the `hostUrl` with the relevant Elasticsearch instance:
+
[source,yaml]
----
apiVersion: infra.watch/v1beta1
kind: ServiceTelemetry
metadata:
  name: default
  namespace: service-telemetry
spec:
  [...]
  backends:
    events:
      elasticsearch:
        enabled: true
        forwarding:
          hostUrl: https://external-elastic-http.domain:9200
          tlsServerName: ""
          tlsSecretName: elasticsearch-es-cert
          userSecretName: elasticsearch-es-elastic-user
          useBasicAuth: true
          useTls: true
----

. Create the secret named in the `userSecretName` parameter to store the basic `auth` credentials
+
[source,bash]
----
$ oc create secret generic elasticsearch-es-elastic-user --from-literal=elastic='<PASSWORD>'
----

. Copy the CA certificate into a file named `EXTERNAL-ES-CA.pem`, then create the secret named in the `tlsSecretName` parameter to make it available to {ProjectShort}
+
[source,bash]
----
$ cat EXTERNAL-ES-CA.pem
-----BEGIN CERTIFICATE-----
[...]
-----END CERTIFICATE-----

$ oc create secret generic elasticsearch-es-cert --from-file=ca.crt=EXTERNAL-ES-CA.pem
----

[id="clouds_{context}"]
[discrete]
== The clouds parameter

Configure the `clouds` parameter to define which Smart Gateway objects deploy and provide the interface for monitored cloud environments to connect to an instance of {ProjectShort}. If a supporting back end is available, metrics and events Smart Gateways for the default cloud configuration are created. By default, the Service Telemetry Operator creates Smart Gateways for `cloud1`.

ifndef::include_when_13[]
You can create a list of cloud objects to control which Smart Gateways are created for the defined clouds. Each cloud consists of data types and collectors. Data types are `metrics` or `events`. Each data type consists of a list of collectors, the message bus subscription address, and a parameter to enable debugging. Available collectors for metrics are `collectd`, `ceilometer`, and `sensubility`. Available collectors for events are `collectd` and `ceilometer`. Ensure that the subscription address for each of these collectors is unique for every cloud, data type, and collector combination.

The default `cloud1` configuration is represented by the following `ServiceTelemetry` object, which provides subscriptions and data storage of metrics and events for collectd, Ceilometer, and Sensubility data collectors for a particular cloud instance:
endif::[]
ifdef::include_when_13[]
You can create a list of cloud objects to control which Smart Gateways are created for the defined clouds. Each cloud consists of data types and collectors. Data types are `metrics` or `events`. Each data type consists of a list of collectors, the message bus subscription address, and a parameter to enable debugging. Available collectors are `collectd`, and `ceilometer`. Ensure that the subscription address for each of these collectors is unique for every cloud, data type, and collector combination.

The default `cloud1` configuration is represented by the following `ServiceTelemetry` object, which provides subscriptions and data storage of metrics and events for collectd, and data collectors for a particular cloud instance:
endif::[]

[source,yaml]
----
apiVersion: infra.watch/v1beta1
kind: ServiceTelemetry
metadata:
  name: default
  namespace: service-telemetry
spec:
  clouds:
    - name: cloud1
      metrics:
        collectors:
          - collectorType: collectd
            subscriptionAddress: collectd/cloud1-telemetry
          - collectorType: ceilometer
            subscriptionAddress: anycast/ceilometer/cloud1-metering.sample
ifndef::include_when_13[]
          - collectorType: sensubility
            subscriptionAddress: sensubility/cloud1-telemetry
            debugEnabled: false
endif::[]
      events:
        collectors:
          - collectorType: collectd
            subscriptionAddress: collectd/cloud1-notify
          - collectorType: ceilometer
            subscriptionAddress: anycast/ceilometer/cloud1-event.sample
----

ifndef::include_when_13[]
Each item of the `clouds` parameter represents a cloud instance. A cloud instance consists of three top-level parameters: `name`, `metrics`, and `events`. The `metrics` and `events` parameters represent the corresponding back end for storage of that data type. The `collectors` parameter specifies a list of objects made up of two required parameters, `collectorType` and `subscriptionAddress`, and these represent an instance of the Smart Gateway. The `collectorType` parameter specifies data collected by either collectd, Ceilometer, or Sensubility. The `subscriptionAddress` parameter provides the {MessageBus} address to which a Smart Gateway subscribes.
endif::[]
ifdef::include_when_13[]
Each item of the `clouds` parameter represents a cloud instance. A cloud instance consists of three top-level parameters: `name`, `metrics`, and `events`. The `metrics` and `events` parameters represent the corresponding back end for storage of that data type. The `collectors` parameter specifies a list of objects made up of two required parameters, `collectorType` and `subscriptionAddress`, and these represent an instance of the Smart Gateway. The `collectorType` parameter specifies data collected by either collectd, or Ceilometer. The `subscriptionAddress` parameter provides the {MessageBus} address to which a Smart Gateway subscribes.
endif::[]

You can use the optional Boolean parameter `debugEnabled` within the `collectors` parameter to enable additional console debugging in the running Smart Gateway pod.

.Additional resources

* For more information about deleting default Smart Gateways, see xref:deleting-the-default-smart-gateways_assembly-completing-the-stf-configuration[].

* For more information about how to configure multiple clouds, see xref:configuring-multiple-clouds_assembly-completing-the-stf-configuration[].

[id="alerting_{context}"]
[discrete]
== The alerting parameter

Set the `alerting` parameter to create an Alertmanager instance and a storage back end. By default, `alerting` is enabled. For more information, see xref:alerts_assembly-advanced-features[].

[id="graphing_{context}"]
[discrete]
== The graphing parameter

Set the `graphing` parameter to create a Grafana instance. By default, `graphing` is disabled. For more information, see xref:dashboards_assembly-advanced-features[].

[id="highAvailability_{context}"]
[discrete]
== The highAvailability parameter

[WARNING]
====
{ProjectShort} high availability (HA) mode is deprecated and is not supported in production environments. {OpenShift} is a highly-available platform, and you can cause issues and complicate debugging in {ProjectShort} if you enable HA mode.
====

Set the `highAvailability` parameter instantiate multiple copies of {ProjectShort} components to reduce recovery time of components that fail or are rescheduled. By default, `highAvailability` is disabled. For more information, see xref:high-availability_assembly-advanced-features[].

[id="transports_{context}"]
[discrete]
== The transports parameter

Set the `transports` parameter to enable the message bus for a {ProjectShort} deployment. The only transport currently supported is {MessageBus}. By default, the `qdr` transport is enabled.
